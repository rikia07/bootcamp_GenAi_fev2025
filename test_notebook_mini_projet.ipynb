{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set Up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract Text from PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs(pdf_path): \n",
    "    \"\"\"\n",
    "    Extrait le texte de chaque page des fichiers PDF fournis,\n",
    "    et combine tout le texte en une seule cha√Æne.\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "\n",
    "    for pdf_path in pdf_path:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            pdf_text = \"\"\n",
    "\n",
    "            for page_num, page in enumerate(reader.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    pdf_text += text + \"\\n\"\n",
    "\n",
    "            print(f\" {os.path.basename(pdf_path)} : {len(reader.pages)} pages extraites.\")\n",
    "            all_text += pdf_text + \"\\n\"\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ich-guideline-good-clinical-practice-e6r2.pdf : 68 pages extraites.\n",
      "\n",
      " Aper√ßu du texte extrait :\n",
      "\n",
      " \n",
      " \n",
      "30 Churchill Place  ‚óè Canary Wharf ‚óè London E14 5EU ‚óè United Kingdom  \n",
      "An agency of the European Union     Telephone  +44 (0)20 3660 6000 Facsimile  +44 (0)20 3660 5555  \n",
      "Send a question via our website  www.ema.europa.eu/contact  \n",
      " \n",
      " \n",
      "¬© European Medicines Agency, 2018. Reproduction is authorised provided the source is acknowledged.  \n",
      " \n",
      "1 December  2016 \n",
      "EMA/CHMP/ICH/135/1995  \n",
      "Committee for Human Medicinal Products  \n",
      "Guideline for good clinical practice E6(R2)  \n",
      "Step 5 \n",
      "Adopted by CHMP for release for consultation  23 July 2015  \n",
      "Start of public consultation   4 August  2015 \n",
      "End of consultation (dea dline for comments)   3 February  2016 \n",
      "Final adoption by CHMP  15 December 2016  \n",
      "Date for coming into effect  14 June 2017  \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 2/68 \n",
      " \n",
      " Document History  \n",
      " \n",
      "First \n",
      "Codification  History  Date New \n",
      "Codification  \n",
      "November \n",
      "2005 \n",
      "E6 Approval by the CPMP  under Step 3 and release for \n",
      "public consult\n"
     ]
    }
   ],
   "source": [
    "# Liste de fichiers PDF √† traiter\n",
    "pdf_files = [\"ich-guideline-good-clinical-practice-e6r2.pdf\"]\n",
    "\n",
    "# Extraction du texte\n",
    "texte_total = extract_text_from_pdfs(pdf_files)\n",
    "\n",
    "# Aper√ßu dans le terminal\n",
    "print(\"\\n Aper√ßu du texte extrait :\\n\")\n",
    "print(texte_total[:1000])  # Affiche les 1000 premiers caract√®res seulement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (0.3.22)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.50)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.23)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    D√©coupe un texte long en chunks de taille d√©finie avec overlap, en utilisant LangChain.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    chunks = splitter.split_text(text)\n",
    "    print(f\" Nombre de chunks cr√©√©s : {len(chunks)}\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Nombre de chunks cr√©√©s : 191\n",
      "\n",
      "--- Chunk 1 ---\n",
      "\n",
      "30 Churchill Place  ‚óè Canary Wharf ‚óè London E14 5EU ‚óè United Kingdom  \n",
      "An agency of the European Union     Telephone  +44 (0)20 3660 6000 Facsimile  +44 (0)20 3660 5555  \n",
      "Send a question via our website  www.ema.europa.eu/contact  \n",
      " \n",
      " \n",
      "¬© European Medicines Agency, 2018. Reproduction is authorised provided the source is acknowledged.  \n",
      " \n",
      "1 December  2016 \n",
      "EMA/CHMP/ICH/135/1995  \n",
      "Committee for Human Medicinal Products  \n",
      "Guideline for good clinical practice E6(R2)  \n",
      "Step 5 \n",
      "Adopted by CHMP for rele\n",
      "\n",
      "--- Chunk 2 ---\n",
      "\n",
      "EMA/CHMP/ICH/135/1995   Page 2/68 \n",
      " \n",
      " Document History  \n",
      " \n",
      "First \n",
      "Codification  History  Date New \n",
      "Codification  \n",
      "November \n",
      "2005 \n",
      "E6 Approval by the CPMP  under Step 3 and release for \n",
      "public consultation.  May 1995  E6 \n",
      "E6 Approval by the CPMP  under Step 4 and released for \n",
      "information . July 1996  E6 \n",
      "Step 5 corrected version  \n",
      "E6 Approval by the CPMP of Post-Step 4  editorial \n",
      "corrections.  July 2002  E6(R1)  \n",
      "Current E6(R2) Addendum Step 5 version  \n",
      "Code History  Date \n",
      "E6 Adoption by the Re\n"
     ]
    }
   ],
   "source": [
    "chunks = split_text_into_chunks(texte_total)\n",
    "\n",
    "# Aper√ßu des 2 premiers chunks :\n",
    "for i, chunk in enumerate(chunks[:2]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "    print(chunk[:500])  # afficher les 500 premiers caract√®res de chaque chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generate Embeddings and Create a a FAISS Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> convertir en vecteurs num√©riques gr√¢ce √† GoogleGenerativeAIEmbeddings\n",
    "--> Les stocker dans une base vectorielle FAISS, pour les interroger plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Extraction du texte (Task 2)\n",
    "‚úÖ Chunking du texte (Task 3)\n",
    "üü¢ Embeddings + FAISS (Task 4)\n",
    "‚¨ú Retrieval & QA chain (Task 5)\n",
    "‚¨ú Streamlit UI (Task 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (0.3.22)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: langchain_google_genai in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.50)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.23)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (4.13.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu langchain google-generativeai langchain_google_genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.charges un outil d‚Äôembedding fourni par Gemini (Google Generative AI)\n",
    "# G√©n√©rer les embeddings avec Gemini\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Charger la cl√© API depuis .env\n",
    "load_dotenv() # fonction qui charge les variables depuis .env\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") # la valeur de la cl√© API depuis le fichier .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl√© API d√©tect√©e : AIzaSy...\n"
     ]
    }
   ],
   "source": [
    "# v√©rification que la cl√© a bien √©t√© r√©cup√©r√©e\n",
    "print(\"Cl√© API d√©tect√©e :\", api_key[:6] + \"...\" if api_key else \" Cl√© non trouv√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Cr√©er l‚Äôoutil d'embedding Gemini avec la cl√©\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Pr√©parer les chunks : transformer les chunks en objets Document (LangChain attend des objets appel√©s Document)\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embeddings g√©n√©r√©s et vector store cr√©√©.\n"
     ]
    }
   ],
   "source": [
    "# 5. G√©n√©rer les embeddings et cr√©er la base FAISS\n",
    "vector_store = FAISS.from_documents(documents, embeddings) # cr√©ation d une base d‚Äôindexation intelligente : chaque chunk de ton PDF est repr√©sent√© en embeding dans FAISS.\n",
    "#  FAISS va :\n",
    "# Lire chaque Document\n",
    "# G√©n√©rer son embedding avec Gemini\n",
    "# Les stocker dans une base pr√™te √† √™tre interrog√©e\n",
    "print(\" Embeddings g√©n√©r√©s et vector store cr√©√©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base FAISS sauvegard√©e dans le dossier 'faiss_index'\n"
     ]
    }
   ],
   "source": [
    "# 6 : Sauvegarder localement la base vectorielle FAISS\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "print(\" Base FAISS sauvegard√©e dans le dossier 'faiss_index'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 : Recharger plus tard (quand l'app red√©marre)\n",
    "vector_store = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fonction generate_and_save_embeddings(chunks): tout est regroup√© sous une focntion\n",
    "# def generate_and_save_embeddings(chunks, index_path=\"faiss_index\"):\n",
    "#     #\"\"\"\n",
    "#     #G√©n√©re les embeddings pour chaque chunk de texte,\n",
    "#     #cr√©e une base vectorielle FAISS et la sauvegarde localement.\n",
    "#     #\"\"\"\n",
    "#     load_dotenv()\n",
    "#     api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "#     if not api_key:\n",
    "#         raise ValueError(\" Cl√© API Google Gemini non trouv√©e dans .env\")\n",
    "\n",
    "#     embeddings = GoogleGenerativeAIEmbeddings(\n",
    "#         model=\"models/embedding-001\",\n",
    "#         google_api_key=api_key\n",
    "#     )\n",
    "#     documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "#     vector_store = FAISS.from_documents(documents, embeddings)\n",
    "#     print(f\"‚úÖ {len(documents)} documents vectoris√©s.\")\n",
    "\n",
    "#     vector_store.save_local(index_path)\n",
    "#     print(f\"‚úÖ Base FAISS sauvegard√©e dans le dossier '{index_path}'.\")\n",
    "\n",
    "#     return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R√©cap du projet pro\n",
    "‚úÖ PDF ‚Üí Texte brut\n",
    "‚úÖ Texte ‚Üí Chunks\n",
    "‚úÖ Chunks ‚Üí Embeddings (Gemini)\n",
    "‚úÖ Embeddings ‚Üí FAISS vector store\n",
    "üü¢ FAISS + Gemini ‚Üí Retrieval QA Chain\n",
    "‚¨ú UI interactive (Streamlit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain(vector_store):\n",
    "    \"\"\"\n",
    "    Cr√©e une cha√Æne de questions/r√©ponses bas√©e sur Gemini + FAISS\n",
    "    avec un prompt personnalis√©.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Cr√©er le mod√®le LLM Gemini\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"models/gemini-1.5-pro-001\",\n",
    "        temperature=0.2  # Stable et factuel\n",
    "    )\n",
    "\n",
    "    # 2. Cr√©er un prompt template personnalis√©\n",
    "    prompt_template = \"\"\"\n",
    "    Tu es un assistant expert en recherche clinique.\n",
    "    R√©ponds de fa√ßon claire et concise √† la question suivante\n",
    "    uniquement √† partir du contexte fourni.\n",
    "\n",
    "    Si l'information ne se trouve pas dans le contexte, dis : \"Je ne sais pas.\"\n",
    "\n",
    "    CONTEXTE :\n",
    "    {context}\n",
    "\n",
    "    QUESTION :\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "\n",
    "    # 3. Cr√©er la cha√Æne QA avec LangChain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        chain_type=\"stuff\",  # Simple, le contexte est inject√© tel quel\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ Cha√Æne QA avec Gemini et FAISS pr√™te √† l'emploi.\")\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cha√Æne QA avec Gemini et FAISS pr√™te √† l'emploi.\n",
      "üìò R√©ponse :\n",
      "     Les essais cliniques doivent √™tre men√©s conform√©ment aux principes √©thiques qui ont leur origine dans la D√©claration d'Helsinki et qui sont conformes aux BPC et aux exigences r√©glementaires applicables.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = create_qa_chain(vector_store)\n",
    "\n",
    "# Pose une question sur ton PDF\n",
    "question = \"Quels sont les principes g√©n√©raux de l'ICH E6 R2 ?\"\n",
    "\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(\"üìò R√©ponse :\\n\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "# code pour afficher les mod√®les dispo :\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testons une question avec Gemini sur ton document\n",
    "question = \"Quelles sont les responsabilit√©s du promoteur dans l'ICH E6 R2 ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò R√©ponse g√©n√©r√©e par Gemini :\n",
      "\n",
      "Avant de commencer un essai, le promoteur doit d√©finir, √©tablir et attribuer toutes les t√¢ches et fonctions li√©es √† l'essai. Le promoteur doit √©galement fournir une assurance ou indemniser l'investigateur/l'institution contre les r√©clamations d√©coulant de l'essai, sauf pour les r√©clamations qui d√©coulent d'une faute professionnelle et/ou d'une n√©gligence. Le promoteur doit √©galement identifier les risques pour les processus et les donn√©es critiques de l'essai et les √©valuer. Le promoteur doit d√©cider quels risques r√©duire et/ou quels risques accepter. \n"
     ]
    }
   ],
   "source": [
    "print(\"R√©ponse g√©n√©r√©e par Gemini :\\n\")\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chunks utilis√©s comme contexte :\n",
      "\n",
      "--- Chunk 1 ---\n",
      "\n",
      "5.5.3 (a), 5.5.3 (b), 5.5.3 (h), 5.18.3, 5.18.6 (e), 5.18.7, 5.20.1, \n",
      "8.1 9 November \n",
      "2016 \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 3/68 \n",
      " \n",
      " Guideline for good clinical practice E6(R2)  \n",
      "Table of contents  \n",
      "Introduction  ................................ ................................ ................................  6 \n",
      "1. Glossary  ................................ ................................ ................................ .. 7 \n",
      "2. The princ\n",
      "\n",
      "--- Chunk 2 ---\n",
      "\n",
      "these docu ments are no longer needed (see 4.9.4 and 5.5.12).   \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 36/68 \n",
      " \n",
      " The sponsor and the investigator/institution should sign the protocol, or an alternative document, to \n",
      "confirm this agreement.  \n",
      "5.7.  Allocation of r esponsibilities  \n",
      "Prior to initiating a trial, the sponsor should define, establish, and allocate all trial - relate d duties and \n",
      "functions.  \n",
      "5.8.  Compensation to subjects and i nvestigato\n",
      "\n",
      "--- Chunk 3 ---\n",
      "\n",
      "ensure human subject protection and the reliability of trial results.  \n",
      "5.0.2.  Risk i dentification  \n",
      "The sponsor should identify risks to c ritical trial proc esses and data. Risks should be considered at both \n",
      "the system level (e.g., standard operating procedures, computerized  systems, personnel) and clinical \n",
      "trial level (e.g., trial design, data collection, informed  consent process).  \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 31/68 \n",
      " \n",
      " 5.0.3.  Ris\n",
      "\n",
      "--- Chunk 4 ---\n",
      "\n",
      "have an impact on the safety and well -being of human subjects.  \n",
      "ADDENDUM  \n",
      "Since the development of the ICH GCP Guideline, the scale, c omplexity, and cost of clinical trials have \n",
      "increased. Evolutions in technology and risk management processes offer new  opportunities to \n",
      "increase efficiency and focus on relevant activities. When the original ICH  E6(R1) text was prepared, \n",
      "clinical trials were performed in a largely paper -based process.  Advance s in use of electronic data \n",
      "recording and \n"
     ]
    }
   ],
   "source": [
    "# Afficher les sources (chunks) utilis√©s\n",
    "print(\"\\n Chunks utilis√©s comme contexte :\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "    print(doc.page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture globale de l‚Äôapp\n",
    "[ PDF Upload ] ‚Üí Extraction ‚Üí Chunking ‚Üí Embedding ‚Üí FAISS\n",
    "\n",
    "[ User Input ] ‚Üí Recherche vectorielle ‚Üí Gemini ‚Üí R√©ponse\n",
    "\n",
    "‚Üí [ Affichage dans le chat Streamlit ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Implement the Chat Interface -->\n",
    "- Ouvre VS Code dans ton dossier projet: v√©rifie que ton fichier projet est bien pr√©sent avec le fichier app.py\n",
    "cd /chemin/vers/projet_Gemini_PDF_Chatbot\n",
    "- Active ton environnement virtuel :source venv/Scripts/activate  # ‚Üê sous Windows avec Git Bash\n",
    "-Lance Streamlit avec app.py : streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
