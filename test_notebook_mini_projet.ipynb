{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set Up the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract Text from PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs(pdf_path): \n",
    "    \"\"\"\n",
    "    Extrait le texte de chaque page des fichiers PDF fournis,\n",
    "    et combine tout le texte en une seule chaîne.\n",
    "    \"\"\"\n",
    "    all_text = \"\"\n",
    "\n",
    "    for pdf_path in pdf_path:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            pdf_text = \"\"\n",
    "\n",
    "            for page_num, page in enumerate(reader.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    pdf_text += text + \"\\n\"\n",
    "\n",
    "            print(f\" {os.path.basename(pdf_path)} : {len(reader.pages)} pages extraites.\")\n",
    "            all_text += pdf_text + \"\\n\"\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ich-guideline-good-clinical-practice-e6r2.pdf : 68 pages extraites.\n",
      "\n",
      " Aperçu du texte extrait :\n",
      "\n",
      " \n",
      " \n",
      "30 Churchill Place  ● Canary Wharf ● London E14 5EU ● United Kingdom  \n",
      "An agency of the European Union     Telephone  +44 (0)20 3660 6000 Facsimile  +44 (0)20 3660 5555  \n",
      "Send a question via our website  www.ema.europa.eu/contact  \n",
      " \n",
      " \n",
      "© European Medicines Agency, 2018. Reproduction is authorised provided the source is acknowledged.  \n",
      " \n",
      "1 December  2016 \n",
      "EMA/CHMP/ICH/135/1995  \n",
      "Committee for Human Medicinal Products  \n",
      "Guideline for good clinical practice E6(R2)  \n",
      "Step 5 \n",
      "Adopted by CHMP for release for consultation  23 July 2015  \n",
      "Start of public consultation   4 August  2015 \n",
      "End of consultation (dea dline for comments)   3 February  2016 \n",
      "Final adoption by CHMP  15 December 2016  \n",
      "Date for coming into effect  14 June 2017  \n",
      " \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 2/68 \n",
      " \n",
      " Document History  \n",
      " \n",
      "First \n",
      "Codification  History  Date New \n",
      "Codification  \n",
      "November \n",
      "2005 \n",
      "E6 Approval by the CPMP  under Step 3 and release for \n",
      "public consult\n"
     ]
    }
   ],
   "source": [
    "# Liste de fichiers PDF à traiter\n",
    "pdf_files = [\"ich-guideline-good-clinical-practice-e6r2.pdf\"]\n",
    "\n",
    "# Extraction du texte\n",
    "texte_total = extract_text_from_pdfs(pdf_files)\n",
    "\n",
    "# Aperçu dans le terminal\n",
    "print(\"\\n Aperçu du texte extrait :\\n\")\n",
    "print(texte_total[:1000])  # Affiche les 1000 premiers caractères seulement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split the Text into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (0.3.22)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.50)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.23)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Découpe un texte long en chunks de taille définie avec overlap, en utilisant LangChain.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    chunks = splitter.split_text(text)\n",
    "    print(f\" Nombre de chunks créés : {len(chunks)}\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nombre de chunks créés : 191\n",
      "\n",
      "--- Chunk 1 ---\n",
      "\n",
      "30 Churchill Place  ● Canary Wharf ● London E14 5EU ● United Kingdom  \n",
      "An agency of the European Union     Telephone  +44 (0)20 3660 6000 Facsimile  +44 (0)20 3660 5555  \n",
      "Send a question via our website  www.ema.europa.eu/contact  \n",
      " \n",
      " \n",
      "© European Medicines Agency, 2018. Reproduction is authorised provided the source is acknowledged.  \n",
      " \n",
      "1 December  2016 \n",
      "EMA/CHMP/ICH/135/1995  \n",
      "Committee for Human Medicinal Products  \n",
      "Guideline for good clinical practice E6(R2)  \n",
      "Step 5 \n",
      "Adopted by CHMP for rele\n",
      "\n",
      "--- Chunk 2 ---\n",
      "\n",
      "EMA/CHMP/ICH/135/1995   Page 2/68 \n",
      " \n",
      " Document History  \n",
      " \n",
      "First \n",
      "Codification  History  Date New \n",
      "Codification  \n",
      "November \n",
      "2005 \n",
      "E6 Approval by the CPMP  under Step 3 and release for \n",
      "public consultation.  May 1995  E6 \n",
      "E6 Approval by the CPMP  under Step 4 and released for \n",
      "information . July 1996  E6 \n",
      "Step 5 corrected version  \n",
      "E6 Approval by the CPMP of Post-Step 4  editorial \n",
      "corrections.  July 2002  E6(R1)  \n",
      "Current E6(R2) Addendum Step 5 version  \n",
      "Code History  Date \n",
      "E6 Adoption by the Re\n"
     ]
    }
   ],
   "source": [
    "chunks = split_text_into_chunks(texte_total)\n",
    "\n",
    "# Aperçu des 2 premiers chunks :\n",
    "for i, chunk in enumerate(chunks[:2]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "    print(chunk[:500])  # afficher les 500 premiers caractères de chaque chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generate Embeddings and Create a a FAISS Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> convertir en vecteurs numériques grâce à GoogleGenerativeAIEmbeddings\n",
    "--> Les stocker dans une base vectorielle FAISS, pour les interroger plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Extraction du texte (Task 2)\n",
    "✅ Chunking du texte (Task 3)\n",
    "🟢 Embeddings + FAISS (Task 4)\n",
    "⬜ Retrieval & QA chain (Task 5)\n",
    "⬜ Streamlit UI (Task 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (0.3.22)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: langchain_google_genai in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from faiss-cpu) (2.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.50)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (0.3.23)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-generativeai) (4.13.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\rickia\\documents\\bootcamp_genai_fev2025\\projets\\projet_gemini_pdf_chatbot\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu langchain google-generativeai langchain_google_genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.charges un outil d’embedding fourni par Gemini (Google Generative AI)\n",
    "# Générer les embeddings avec Gemini\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Charger la clé API depuis .env\n",
    "load_dotenv() # fonction qui charge les variables depuis .env\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\") # la valeur de la clé API depuis le fichier .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clé API détectée : AIzaSy...\n"
     ]
    }
   ],
   "source": [
    "# vérification que la clé a bien été récupérée\n",
    "print(\"Clé API détectée :\", api_key[:6] + \"...\" if api_key else \" Clé non trouvée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Créer l’outil d'embedding Gemini avec la clé\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Préparer les chunks : transformer les chunks en objets Document (LangChain attend des objets appelés Document)\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Embeddings générés et vector store créé.\n"
     ]
    }
   ],
   "source": [
    "# 5. Générer les embeddings et créer la base FAISS\n",
    "vector_store = FAISS.from_documents(documents, embeddings) # création d une base d’indexation intelligente : chaque chunk de ton PDF est représenté en embeding dans FAISS.\n",
    "#  FAISS va :\n",
    "# Lire chaque Document\n",
    "# Générer son embedding avec Gemini\n",
    "# Les stocker dans une base prête à être interrogée\n",
    "print(\" Embeddings générés et vector store créé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base FAISS sauvegardée dans le dossier 'faiss_index'\n"
     ]
    }
   ],
   "source": [
    "# 6 : Sauvegarder localement la base vectorielle FAISS\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "print(\" Base FAISS sauvegardée dans le dossier 'faiss_index'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 : Recharger plus tard (quand l'app redémarre)\n",
    "vector_store = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fonction generate_and_save_embeddings(chunks): tout est regroupé sous une focntion\n",
    "# def generate_and_save_embeddings(chunks, index_path=\"faiss_index\"):\n",
    "#     #\"\"\"\n",
    "#     #Génére les embeddings pour chaque chunk de texte,\n",
    "#     #crée une base vectorielle FAISS et la sauvegarde localement.\n",
    "#     #\"\"\"\n",
    "#     load_dotenv()\n",
    "#     api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "#     if not api_key:\n",
    "#         raise ValueError(\" Clé API Google Gemini non trouvée dans .env\")\n",
    "\n",
    "#     embeddings = GoogleGenerativeAIEmbeddings(\n",
    "#         model=\"models/embedding-001\",\n",
    "#         google_api_key=api_key\n",
    "#     )\n",
    "#     documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "#     vector_store = FAISS.from_documents(documents, embeddings)\n",
    "#     print(f\"✅ {len(documents)} documents vectorisés.\")\n",
    "\n",
    "#     vector_store.save_local(index_path)\n",
    "#     print(f\"✅ Base FAISS sauvegardée dans le dossier '{index_path}'.\")\n",
    "\n",
    "#     return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récap du projet pro\n",
    "✅ PDF → Texte brut\n",
    "✅ Texte → Chunks\n",
    "✅ Chunks → Embeddings (Gemini)\n",
    "✅ Embeddings → FAISS vector store\n",
    "🟢 FAISS + Gemini → Retrieval QA Chain\n",
    "⬜ UI interactive (Streamlit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain(vector_store):\n",
    "    \"\"\"\n",
    "    Crée une chaîne de questions/réponses basée sur Gemini + FAISS\n",
    "    avec un prompt personnalisé.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Créer le modèle LLM Gemini\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"models/gemini-1.5-pro-001\",\n",
    "        temperature=0.2  # Stable et factuel\n",
    "    )\n",
    "\n",
    "    # 2. Créer un prompt template personnalisé\n",
    "    prompt_template = \"\"\"\n",
    "    Tu es un assistant expert en recherche clinique.\n",
    "    Réponds de façon claire et concise à la question suivante\n",
    "    uniquement à partir du contexte fourni.\n",
    "\n",
    "    Si l'information ne se trouve pas dans le contexte, dis : \"Je ne sais pas.\"\n",
    "\n",
    "    CONTEXTE :\n",
    "    {context}\n",
    "\n",
    "    QUESTION :\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "\n",
    "    # 3. Créer la chaîne QA avec LangChain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        chain_type=\"stuff\",  # Simple, le contexte est injecté tel quel\n",
    "        chain_type_kwargs={\"prompt\": prompt},\n",
    "        return_source_documents=True\n",
    "    )\n",
    "\n",
    "    print(\"✅ Chaîne QA avec Gemini et FAISS prête à l'emploi.\")\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chaîne QA avec Gemini et FAISS prête à l'emploi.\n",
      "📘 Réponse :\n",
      "     Les essais cliniques doivent être menés conformément aux principes éthiques qui ont leur origine dans la Déclaration d'Helsinki et qui sont conformes aux BPC et aux exigences réglementaires applicables.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = create_qa_chain(vector_store)\n",
    "\n",
    "# Pose une question sur ton PDF\n",
    "question = \"Quels sont les principes généraux de l'ICH E6 R2 ?\"\n",
    "\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(\"📘 Réponse :\\n\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "# code pour afficher les modèles dispo :\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "models = genai.list_models()\n",
    "for m in models:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testons une question avec Gemini sur ton document\n",
    "question = \"Quelles sont les responsabilités du promoteur dans l'ICH E6 R2 ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Réponse générée par Gemini :\n",
      "\n",
      "Avant de commencer un essai, le promoteur doit définir, établir et attribuer toutes les tâches et fonctions liées à l'essai. Le promoteur doit également fournir une assurance ou indemniser l'investigateur/l'institution contre les réclamations découlant de l'essai, sauf pour les réclamations qui découlent d'une faute professionnelle et/ou d'une négligence. Le promoteur doit également identifier les risques pour les processus et les données critiques de l'essai et les évaluer. Le promoteur doit décider quels risques réduire et/ou quels risques accepter. \n"
     ]
    }
   ],
   "source": [
    "print(\"Réponse générée par Gemini :\\n\")\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Chunks utilisés comme contexte :\n",
      "\n",
      "--- Chunk 1 ---\n",
      "\n",
      "5.5.3 (a), 5.5.3 (b), 5.5.3 (h), 5.18.3, 5.18.6 (e), 5.18.7, 5.20.1, \n",
      "8.1 9 November \n",
      "2016 \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 3/68 \n",
      " \n",
      " Guideline for good clinical practice E6(R2)  \n",
      "Table of contents  \n",
      "Introduction  ................................ ................................ ................................  6 \n",
      "1. Glossary  ................................ ................................ ................................ .. 7 \n",
      "2. The princ\n",
      "\n",
      "--- Chunk 2 ---\n",
      "\n",
      "these docu ments are no longer needed (see 4.9.4 and 5.5.12).   \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 36/68 \n",
      " \n",
      " The sponsor and the investigator/institution should sign the protocol, or an alternative document, to \n",
      "confirm this agreement.  \n",
      "5.7.  Allocation of r esponsibilities  \n",
      "Prior to initiating a trial, the sponsor should define, establish, and allocate all trial - relate d duties and \n",
      "functions.  \n",
      "5.8.  Compensation to subjects and i nvestigato\n",
      "\n",
      "--- Chunk 3 ---\n",
      "\n",
      "ensure human subject protection and the reliability of trial results.  \n",
      "5.0.2.  Risk i dentification  \n",
      "The sponsor should identify risks to c ritical trial proc esses and data. Risks should be considered at both \n",
      "the system level (e.g., standard operating procedures, computerized  systems, personnel) and clinical \n",
      "trial level (e.g., trial design, data collection, informed  consent process).  \n",
      " \n",
      " \n",
      " \n",
      "Guideline for good clinical practice E6(R2)    \n",
      "EMA/CHMP/ICH/135/1995   Page 31/68 \n",
      " \n",
      " 5.0.3.  Ris\n",
      "\n",
      "--- Chunk 4 ---\n",
      "\n",
      "have an impact on the safety and well -being of human subjects.  \n",
      "ADDENDUM  \n",
      "Since the development of the ICH GCP Guideline, the scale, c omplexity, and cost of clinical trials have \n",
      "increased. Evolutions in technology and risk management processes offer new  opportunities to \n",
      "increase efficiency and focus on relevant activities. When the original ICH  E6(R1) text was prepared, \n",
      "clinical trials were performed in a largely paper -based process.  Advance s in use of electronic data \n",
      "recording and \n"
     ]
    }
   ],
   "source": [
    "# Afficher les sources (chunks) utilisés\n",
    "print(\"\\n Chunks utilisés comme contexte :\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "    print(doc.page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture globale de l’app\n",
    "[ PDF Upload ] → Extraction → Chunking → Embedding → FAISS\n",
    "\n",
    "[ User Input ] → Recherche vectorielle → Gemini → Réponse\n",
    "\n",
    "→ [ Affichage dans le chat Streamlit ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Implement the Chat Interface -->\n",
    "- Ouvre VS Code dans ton dossier projet: vérifie que ton fichier projet est bien présent avec le fichier app.py\n",
    "cd /chemin/vers/projet_Gemini_PDF_Chatbot\n",
    "- Active ton environnement virtuel :source venv/Scripts/activate  # ← sous Windows avec Git Bash\n",
    "-Lance Streamlit avec app.py : streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
